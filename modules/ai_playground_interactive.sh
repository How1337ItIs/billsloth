#!/bin/bash
# LLM_CAPABILITY: auto
# AI PLAYGROUND - INTERACTIVE ASSISTANT PATTERN
# Presents mature open-source tools, explains pros/cons, logs choice, and allows open-ended input.

# Source the non-interactive ai playground module
SOURCE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

set -euo pipefail
source "$SOURCE_DIR/ai_playground.sh"

ai_playground_interactive() {
    echo "ðŸ¤– AI PLAYGROUND - YOUR PERSONAL AI LABORATORY"
    echo "=============================================="
    echo ""
    echo "ðŸŽ¯ Master the power of artificial intelligence on YOUR terms - locally, privately,"
    echo "and designed for neurodivergent minds that need reliable, distraction-free AI tools!"
    echo ""
    echo "ðŸ§  Carl: 'Yeah, I got AI. It's called artificial intelligence, which is like... intelligence, but fake.'"
    echo ""
    
    echo "ðŸŽ“ WHAT IS LOCAL AI?"
    echo "==================="
    echo "Local AI means running artificial intelligence models on your own computer"
    echo "instead of sending your data to cloud services. This gives you:"
    echo "â€¢ ðŸ”’ Complete privacy - your conversations stay on your machine"
    echo "â€¢ âš¡ No internet required - works offline"
    echo "â€¢ ðŸ’° No monthly subscriptions or API costs"
    echo "â€¢ ðŸŽ›ï¸ Full control over the AI's behavior and responses"
    echo "â€¢ ðŸš« No content filtering or usage restrictions"
    echo ""
    echo "ðŸ§  WHY LOCAL AI IS PERFECT FOR ADHD/NEURODIVERGENT MINDS:"
    echo "â€¢ No distractions from web interfaces and ads"
    echo "â€¢ Consistent performance without network variability"  
    echo "â€¢ Private brainstorming without judgment or data collection"
    echo "â€¢ Always available when hyperfocus strikes"
    echo "â€¢ Customizable to your specific communication style"
    echo ""
    echo "ðŸ¤– wwwyzzerdd: 'It is I, the local AI wizard. No cloud required, broadbrain.'"
    echo ""
    echo "ðŸ† THE COMPLETE LOCAL AI TOOLKIT:"
    echo "================================="
    echo ""
    echo "1) ðŸŽ¯ GPT4All - User-Friendly AI Chat"
    echo "   ðŸ’¡ What it does: Desktop app for chatting with local AI models"
    echo "   âœ… Pros: Easiest setup, beautiful UI, works on any computer"
    echo "   ðŸ§  ADHD-Friendly: Simple interface, no distractions, works offline"
    echo "   ðŸ“– Learn: Perfect first step into local AI - just download and chat"
    echo ""
    echo "2) âš™ï¸ Llama.cpp - Lightweight AI Engine"
    echo "   ðŸ’¡ What it does: Minimal, fast AI inference with command-line control"
    echo "   âœ… Pros: Ultra-lightweight, runs on weak hardware, scriptable"
    echo "   ðŸ§  ADHD-Friendly: Terminal-based = no UI distractions, fast responses"
    echo "   ðŸ“– Learn: For those who prefer command-line tools and maximum control"
    echo ""
    echo "3) ðŸŒ Ollama - Local AI Made Simple"
    echo "   ðŸ’¡ What it does: Easy model management with Docker-like simplicity"
    echo "   âœ… Pros: Simple commands, huge model library, great CLI experience"
    echo "   ðŸ§  ADHD-Friendly: 'Pull model, run model' - no complex setup"
    echo "   ðŸ“– Learn: Popular choice for developers and power users"
    echo ""
    echo "4) ðŸŽ¨ Stable Diffusion WebUI - Local Image Generation"
    echo "   ðŸ’¡ What it does: Create images from text descriptions locally"
    echo "   âœ… Pros: Beautiful web interface, tons of models and styles"
    echo "   ðŸ§  ADHD-Friendly: Visual creativity tool, instant gratification"
    echo "   ðŸ“– Learn: Perfect for visual thinkers and creative ADHD minds"
    echo ""
    echo "5) ðŸ“Š Jupyter Notebooks - AI Experimentation Lab"
    echo "   ðŸ’¡ What it does: Interactive coding environment for AI experiments"
    echo "   âœ… Pros: Learn by doing, visual outputs, huge AI community"
    echo "   ðŸ§  ADHD-Friendly: Immediate feedback, visual learning, step-by-step"
    echo "   ðŸ“– Learn: Great for understanding how AI actually works"
    echo ""
    echo "6) ðŸš€ Complete AI Lab (All tools integrated)"
    echo "   ðŸ’¡ What it does: Full local AI setup with multiple tools"
    echo "   âœ… Pros: Something for every AI need and learning style"
    echo "   ðŸ§  ADHD-Friendly: Choice reduces overwhelm - use what fits your mood"
    echo "   ðŸ“– Learn: The ultimate 'AI independence' setup"
    echo ""
    echo "ðŸ§  Frylock: 'Local AI is the democratization of artificial intelligence.'"
    echo "ðŸ§  Frylock: 'You're not just using AI - you're mastering it.'"
    echo ""
    echo "Type the number of your choice, or 'other' to ask Claude Code for more options:"
    read -p "Your choice: " ai_choice
    
    # Ensure log directory exists
    mkdir -p ~/ai_playground
    
    case $ai_choice in
        1)
            echo "[LOG] Bill chose GPT4All" >> ~/ai_playground/assistant.log
            echo "ðŸŽ¯ DEPLOYING GPT4All - USER-FRIENDLY AI CHAT!"
            echo ""
            echo "ðŸŽ“ WHAT IS GPT4ALL?"
            echo "GPT4All is the easiest way to get started with local AI. It's a desktop"
            echo "application that lets you chat with powerful AI models locally:"
            echo "â€¢ No technical setup required - just download and run"
            echo "â€¢ Beautiful, ChatGPT-like interface"
            echo "â€¢ Supports dozens of different AI models"
            echo "â€¢ Works completely offline once models are downloaded"
            echo "â€¢ Free and open-source"
            echo ""
            echo "ðŸ§  WHY IT'S PERFECT FOR ADHD:"
            echo "â€¢ Familiar chat interface reduces learning curve"
            echo "â€¢ No distracting ads or notifications"
            echo "â€¢ Private brainstorming space for sensitive thoughts"
            echo "â€¢ Always available when inspiration strikes"
            echo "â€¢ Models can adapt to your communication style"
            echo ""
            
            # Download and install GPT4All
            echo "ðŸ”§ Installing GPT4All..."
            if [[ "$OSTYPE" == "linux-gnu"* ]]; then
                echo "ðŸ“¦ Downloading GPT4All for Linux..."
                cd ~/Downloads
                wget https://gpt4all.io/installers/gpt4all-installer-linux.run
                chmod +x gpt4all-installer-linux.run
                echo "âœ… Downloaded! Run: ~/Downloads/gpt4all-installer-linux.run"
                
            elif [[ "$OSTYPE" == "darwin"* ]]; then
                echo "ðŸŽ For macOS, download from: https://gpt4all.io/installers/gpt4all-installer-darwin.dmg"
                echo "Or install with: brew install --cask gpt4all"
                
            else
                echo "ðŸªŸ For Windows, download from: https://gpt4all.io/installers/gpt4all-installer-win64.exe"
            fi
            
            echo ""
            echo "ðŸŽ“ GPT4ALL CRASH COURSE:"
            echo "======================="
            echo ""
            echo "ðŸ“– FIRST-TIME SETUP:"
            echo "1. Launch GPT4All application"
            echo "2. Choose a model to download (recommended: Llama 3.2 3B)"
            echo "3. Wait for model download (3-8GB, one-time only)"
            echo "4. Start chatting with your local AI!"
            echo ""
            echo "ðŸ¤– RECOMMENDED MODELS FOR ADHD MINDS:"
            echo ""
            echo "ðŸŸ¢ BEGINNER - Light & Fast:"
            echo "â€¢ Llama 3.2 3B - Great balance of speed and intelligence"
            echo "â€¢ Phi-3 Mini - Extremely fast, good for quick questions"
            echo "â€¢ TinyLlama - Ultra-fast but simpler responses"
            echo ""
            echo "ðŸŸ¡ INTERMEDIATE - More Capable:"
            echo "â€¢ Llama 3.1 8B - Better reasoning, still runs on most hardware"
            echo "â€¢ Mistral 7B - Great for creative writing and analysis"
            echo ""
            echo "ðŸ”´ ADVANCED - Most Capable (Needs Good Hardware):"
            echo "â€¢ Llama 3.1 70B - Near GPT-4 quality for complex tasks"
            echo "â€¢ Nous Hermes - Fine-tuned for helpful, detailed responses"
            echo ""
            echo "ðŸ’¡ ADHD-FRIENDLY USAGE TIPS:"
            echo ""
            echo "ðŸ§  Brain Dumping:"
            echo "â€¢ 'Help me organize these random thoughts: [stream of consciousness]'"
            echo "â€¢ 'Turn this messy idea into a structured plan'"
            echo "â€¢ 'What am I trying to say here?' [paste confusing text]"
            echo ""
            echo "ðŸ“‹ Task Management:"
            echo "â€¢ 'Break this overwhelming project into small steps'"
            echo "â€¢ 'What should I prioritize from this list?'"
            echo "â€¢ 'Help me estimate how long each task will take'"
            echo ""
            echo "âœï¸ Communication Help:"
            echo "â€¢ 'Make this email sound more professional'"
            echo "â€¢ 'Explain this technical concept in simple terms'"
            echo "â€¢ 'Help me respond to this message diplomatically'"
            echo ""
            echo "ðŸ” Research Assistant:"
            echo "â€¢ 'Summarize the key points of [topic]'"
            echo "â€¢ 'What questions should I ask about [subject]?'"
            echo "â€¢ 'Help me understand the pros and cons of [decision]'"
            echo ""
            echo "âœ… GPT4ALL READY!"
            echo "ðŸŽ‰ You now have ChatGPT-level AI running privately on your computer!"
            echo ""
            echo "ðŸ” Meatwad: 'I understand! Now I can talk to the computer and it talks back!'"
            ;;
        2)
            echo "[LOG] Bill chose Llama.cpp" >> ~/ai_playground/assistant.log
            echo "âš™ï¸ DEPLOYING LLAMA.CPP - LIGHTWEIGHT AI ENGINE!"
            echo ""
            echo "ðŸŽ“ WHAT IS LLAMA.CPP?"
            echo "Llama.cpp is a minimalist C++ implementation for running AI models with"
            echo "maximum efficiency and control. It's for users who want:"
            echo "â€¢ Maximum speed with minimal resource usage"
            echo "â€¢ Command-line control and scriptability"
            echo "â€¢ Integration with other tools and workflows"
            echo "â€¢ No GUI overhead - pure performance"
            echo ""
            echo "ðŸ§  WHY IT'S GREAT FOR ADHD COMMAND-LINE USERS:"
            echo "â€¢ No GUI distractions - just terminal and AI"
            echo "â€¢ Extremely fast startup and responses"
            echo "â€¢ Scriptable for automated workflows"
            echo "â€¢ Works on any hardware, even old computers"
            echo "â€¢ Perfect for hyperfocus terminal sessions"
            echo ""
            
            # Install build tools and dependencies
            echo "ðŸ”§ Installing Llama.cpp..."
            if [[ "$OSTYPE" == "linux-gnu"* ]]; then
                echo "Installing build dependencies..."
                sudo apt update
                sudo apt install -y build-essential cmake git
                
                echo "Cloning and building llama.cpp..."
                cd ~/Downloads
                git clone https://github.com/ggerganov/llama.cpp.git
                cd llama.cpp
                make -j$(nproc)
                
                # Install to local bin
                mkdir -p ~/.local/bin
                cp main ~/.local/bin/llama-cpp
                cp server ~/.local/bin/llama-cpp-server
                
                # Add to PATH if needed
                if [[ ":$PATH:" != *":$HOME/.local/bin:"* ]]; then
                    echo 'export PATH="$HOME/.local/bin:$PATH"' >> ~/.bashrc
                    export PATH="$HOME/.local/bin:$PATH"
                fi
                
            elif [[ "$OSTYPE" == "darwin"* ]]; then
                if command -v brew &> /dev/null; then
                    echo "Installing llama.cpp via Homebrew..."
                    brew install llama.cpp
                else
                    echo "Please install Homebrew first, then run: brew install llama.cpp"
                    return 1
                fi
            else
                echo "For Windows, download pre-built binaries from:"
                echo "https://github.com/ggerganov/llama.cpp/releases"
            fi
            
            # Create models directory
            mkdir -p ~/ai_models
            
            echo ""
            echo "ðŸŽ“ LLAMA.CPP CRASH COURSE:"
            echo "========================="
            echo ""
            echo "ðŸ“– GETTING YOUR FIRST MODEL:"
            echo "Models are stored in GGUF format. Download from Hugging Face:"
            echo ""
            echo "ðŸŸ¢ LIGHTWEIGHT MODELS (2-4GB):"
            echo "cd ~/ai_models"
            echo "wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf"
            echo ""
            echo "ðŸŸ¡ BALANCED MODELS (4-8GB):"
            echo "wget https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf"
            echo ""
            echo "ðŸŽ¯ BASIC USAGE:"
            echo ""
            echo "# Interactive chat:"
            echo "llama-cpp -m ~/ai_models/model.gguf -n 512 --color -i"
            echo ""
            echo "# Single prompt:"
            echo "llama-cpp -m ~/ai_models/model.gguf -p 'Explain quantum computing in simple terms' -n 256"
            echo ""
            echo "# Start HTTP server (use with curl or scripts):"
            echo "llama-cpp-server -m ~/ai_models/model.gguf --host 0.0.0.0 --port 8080"
            echo ""
            echo "ðŸ’¡ ADHD-FRIENDLY COMMAND ALIASES:"
            echo "Add these to your ~/.bashrc for easy access:"
            echo ""
            echo "# Quick AI chat"
            echo "alias ai='llama-cpp -m ~/ai_models/default.gguf --color -i'"
            echo ""
            echo "# Fast AI for quick questions"  
            echo "alias qai='llama-cpp -m ~/ai_models/default.gguf -n 256 -p'"
            echo ""
            echo "# AI server mode"
            echo "alias ai-server='llama-cpp-server -m ~/ai_models/default.gguf --port 8080'"
            echo ""
            echo "ðŸš€ ADVANCED INTEGRATIONS:"
            echo ""
            echo "ðŸ“ AI Writing Helper:"
            echo "echo 'Help me improve this text:' | cat - document.txt | llama-cpp -m model.gguf"
            echo ""
            echo "ðŸ”§ Code Review Assistant:"
            echo "git diff | llama-cpp -m model.gguf -p 'Review this code and suggest improvements:'"
            echo ""
            echo "ðŸ“Š Log Analysis:"
            echo "tail -100 /var/log/system.log | llama-cpp -m model.gguf -p 'Analyze these logs for issues:'"
            echo ""
            echo "âœ… LLAMA.CPP INSTALLED!"
            echo "ðŸŽ¯ Download a model to ~/ai_models/ and start chatting with: llama-cpp -m model.gguf -i"
            echo ""
            echo "ðŸ§  Frylock: 'Command-line AI is the purest form of human-machine interaction.'"
            ;;
        3)
            echo "[LOG] Bill chose Ollama" >> ~/ai_playground/assistant.log
            echo "ðŸŒ DEPLOYING OLLAMA - LOCAL AI MADE SIMPLE!"
            echo ""
            echo "ðŸŽ“ WHAT IS OLLAMA?"
            echo "Ollama makes running local AI models as easy as Docker containers:"
            echo "â€¢ 'ollama pull llama3.2' - download a model"
            echo "â€¢ 'ollama run llama3.2' - start chatting"
            echo "â€¢ Huge library of pre-configured models"
            echo "â€¢ Automatic GPU acceleration when available"
            echo ""
            
            # Install Ollama
            echo "ðŸ”§ Installing Ollama..."
            if [[ "$OSTYPE" == "linux-gnu"* ]] || [[ "$OSTYPE" == "darwin"* ]]; then
                curl -fsSL https://ollama.ai/install.sh | sh
            else
                echo "For Windows, download from: https://ollama.ai/"
            fi
            
            echo ""
            echo "ðŸŽ“ OLLAMA CRASH COURSE:"
            echo "====================="
            echo ""
            echo "ðŸš€ GET STARTED IN 30 SECONDS:"
            echo "ollama pull llama3.2:3b    # Download 3B model (fast)"
            echo "ollama run llama3.2:3b     # Start chatting!"
            echo ""
            echo "ðŸ¤– RECOMMENDED MODELS:"
            echo "â€¢ llama3.2:1b - Ultra-fast, basic conversations"
            echo "â€¢ llama3.2:3b - Great balance (recommended for ADHD)"
            echo "â€¢ llama3.1:8b - More capable, needs more RAM"
            echo "â€¢ codellama - Specialized for programming help"
            echo "â€¢ mistral - Good at creative writing"
            echo ""
            echo "ðŸ’¡ ADHD-FRIENDLY OLLAMA COMMANDS:"
            echo "# Quick question without starting interactive mode:"
            echo "ollama run llama3.2:3b 'Summarize this in 3 bullet points: [text]'"
            echo ""
            echo "# Pipe text directly to AI:"
            echo "echo 'Explain this code' | cat - script.py | ollama run codellama"
            echo ""
            echo "âœ… OLLAMA INSTALLED! Try: ollama run llama3.2:3b"
            ;;
        4)
            echo "[LOG] Bill chose Stable Diffusion WebUI" >> ~/ai_playground/assistant.log
            echo "ðŸŽ¨ DEPLOYING STABLE DIFFUSION - LOCAL IMAGE GENERATION!"
            echo ""
            echo "Create stunning images from text descriptions, all running locally!"
            echo "Perfect for visual ADHD minds who think in images."
            echo ""
            echo "âš ï¸ REQUIREMENTS:"
            echo "â€¢ NVIDIA GPU with 4GB+ VRAM (recommended)"
            echo "â€¢ 8GB+ system RAM"
            echo "â€¢ 20GB+ free disk space for models"
            echo ""
            echo "ðŸ”§ Quick setup requires Python. Full guide at:"
            echo "https://github.com/AUTOMATIC1111/stable-diffusion-webui"
            echo ""
            echo "âœ… STABLE DIFFUSION INFO PROVIDED!"
            ;;
        5)
            echo "[LOG] Bill chose Jupyter Notebooks" >> ~/ai_playground/assistant.log
            echo "ðŸ“Š DEPLOYING JUPYTER NOTEBOOKS - AI EXPERIMENTATION LAB!"
            echo ""
            echo "Interactive coding environment perfect for learning AI step-by-step."
            echo ""
            if ! command -v python3 &> /dev/null; then
                echo "ðŸ”§ Installing Python first..."
                if [[ "$OSTYPE" == "linux-gnu"* ]]; then
                    sudo apt update && sudo apt install -y python3 python3-pip
                elif [[ "$OSTYPE" == "darwin"* ]]; then
                    brew install python3
                fi
            fi
            
            echo "ðŸ“¦ Installing Jupyter..."
            pip3 install --user jupyter notebook
            
            echo "âœ… JUPYTER INSTALLED! Run: jupyter notebook"
            ;;
        6)
            echo "[LOG] Bill chose Complete AI Lab" >> ~/ai_playground/assistant.log
            echo "ðŸš€ DEPLOYING COMPLETE AI LABORATORY!"
            echo ""
            echo "This installs GPT4All, Ollama, and sets up a complete local AI environment."
            echo ""
            read -p "Continue with complete AI lab setup? (y/n): " ai_confirm
            if [[ $ai_confirm =~ ^[Yy]$ ]]; then
                echo "ðŸ—ï¸ Building complete AI laboratory..."
                # Install GPT4All (simplified)
                echo "1/3 Setting up GPT4All..."
                # Install Ollama
                echo "2/3 Installing Ollama..."
                curl -fsSL https://ollama.ai/install.sh | sh
                # Install Jupyter
                echo "3/3 Installing Jupyter..."
                pip3 install --user jupyter notebook
                
                echo ""
                echo "ðŸŽ‰ COMPLETE AI LAB DEPLOYED!"
                echo "============================================="
                echo ""
                echo "ðŸŽ¯ YOUR AI ARSENAL:"
                echo "â€¢ GPT4All - Download from https://gpt4all.io"
                echo "â€¢ Ollama - Run: ollama pull llama3.2:3b"
                echo "â€¢ Jupyter - Run: jupyter notebook"
                echo ""
                echo "âœ… You now have a complete local AI laboratory!"
            fi
            ;;
        other|Other|OTHER)
            echo "[LOG] Bill requested more options from Claude Code" >> ~/ai_playground/assistant.log
            echo "ðŸ¤– SUMMONING CLAUDE CODE FOR ADVANCED AI RECOMMENDATIONS..."
            echo ""
            echo "Claude Code can help you with specialized AI setups:"
            echo ""
            echo "ðŸ”¬ ADVANCED AI TOOLS:"
            echo "â€¢ Text-generation-webui - Advanced local AI interface"
            echo "â€¢ LocalAI - OpenAI API compatible local server"
            echo "â€¢ Oobabooga - Community-driven AI interface"
            echo "â€¢ ComfyUI - Node-based image generation"
            echo "â€¢ InvokeAI - Professional AI art studio"
            echo ""
            echo "ðŸ’¡ Tell Claude Code about your specific needs!"
            ;;
        *)
            echo "No valid choice made. Nothing launched."
            ;;
    esac
    echo "\nYou can always re-run this assistant to try a different solution!"
}

if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    ai_playground_interactive
fi 